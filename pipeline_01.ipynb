{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXobIQso5QrG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ----------------------------\n",
        "# Fun√ß√£o 1: Pr√©-processamento e Feature Engineering\n",
        "# ----------------------------\n",
        "def preprocess_data(df, target='Carga_Tra√ßao', drop_cols=None):\n",
        "    if drop_cols is None:\n",
        "        drop_cols = ['ID', 'Argila', 'Areia', 'Silte', 'Torque Max. (kgf.m)',\n",
        "                     'E(Mpa)', 'Nspt_qc_product']\n",
        "    df = df.drop(columns=drop_cols, errors='ignore')\n",
        "\n",
        "    # Normalizar alvo\n",
        "    scaler_y = MinMaxScaler()\n",
        "    df[target] = scaler_y.fit_transform(df[[target]])\n",
        "\n",
        "    # Interpola√ß√£o de Nspt com profundidade\n",
        "    mask = df['Nspt'].notnull() & df['Deph(m)'].notnull()\n",
        "    if mask.sum() > 1:\n",
        "        df['Nspt'] = np.interp(df['Deph(m)'], df['Deph(m)'][mask], df['Nspt'][mask])\n",
        "\n",
        "    # Engenharia de atributos\n",
        "    df['Nspt_qc_ratio'] = df['Nspt'] / (df['qc(Mpa)'] + 1e-8)\n",
        "    df['Depth_fs_product'] = df['Deph(m)'] * df['fs(Mpa)']\n",
        "    df['Nspt_carga_product'] = df['Nspt'] * df[target]\n",
        "    df['log_Nspt'] = np.log1p(df['Nspt'])\n",
        "\n",
        "    # Winsoriza√ß√£o\n",
        "    Q1 = df['Nspt_carga_product'].quantile(0.25)\n",
        "    Q3 = df['Nspt_carga_product'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    df['Nspt_carga_product'] = df['Nspt_carga_product'].clip(Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)\n",
        "\n",
        "    df['log_Nspt_carga_product'] = np.log1p(df['Nspt_carga_product'])\n",
        "\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # Imputa√ß√£o\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "    imputer = IterativeImputer(random_state=42)\n",
        "    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "    # Corrigir valores f√≠sicos\n",
        "    non_negative_cols = ['Deph(m)', 'Nspt', 'qc(Mpa)', 'fs(Mpa)',\n",
        "                         'Depth_fs_product', 'Nspt_qc_ratio']\n",
        "    df[non_negative_cols] = df[non_negative_cols].clip(lower=0)\n",
        "\n",
        "    # Normaliza√ß√£o das features\n",
        "    features_to_normalize = ['Deph(m)', 'Nspt', 'qc(Mpa)', 'fs(Mpa)',\n",
        "                             'Depth_fs_product', 'Nspt_qc_ratio', 'log_Nspt_carga_product']\n",
        "    scaler_X = MinMaxScaler()\n",
        "    df[features_to_normalize] = scaler_X.fit_transform(df[features_to_normalize])\n",
        "\n",
        "    return df, scaler_X, scaler_y\n",
        "\n",
        "# ----------------------------\n",
        "# Fun√ß√£o 2: Treinar modelo\n",
        "# ----------------------------\n",
        "def train_model(df, target='Carga_Tra√ßao'):\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = VotingRegressor(estimators=[\n",
        "        ('xgb', XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=6, random_state=42)),\n",
        "        ('rf', RandomForestRegressor(n_estimators=300, max_depth=10, random_state=42))\n",
        "    ])\n",
        "\n",
        "    pipeline = Pipeline([('model', model)])\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f'\\nüîç Avalia√ß√£o do Modelo:')\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'R¬≤: {r2:.4f}')\n",
        "\n",
        "    return pipeline, X.columns\n",
        "\n",
        "# ----------------------------\n",
        "# Fun√ß√£o 3: Prever novo valor\n",
        "# ----------------------------\n",
        "def predict_new_case(pipeline, new_data, feature_names, scaler_X, scaler_y):\n",
        "    # Recriar features no novo dado\n",
        "    new_data['Nspt_qc_ratio'] = new_data['Nspt'] / (new_data['qc(Mpa)'] + 1e-8)\n",
        "    new_data['Depth_fs_product'] = new_data['Deph(m)'] * new_data['fs(Mpa)']\n",
        "    new_data['Nspt_carga_product'] = 0\n",
        "    new_data['log_Nspt'] = np.log1p(new_data['Nspt'])\n",
        "    new_data['log_Nspt_carga_product'] = np.log1p(new_data['Nspt_carga_product'])\n",
        "\n",
        "    # Normalizar features\n",
        "    features_to_normalize = ['Deph(m)', 'Nspt', 'qc(Mpa)', 'fs(Mpa)',\n",
        "                             'Depth_fs_product', 'Nspt_qc_ratio', 'log_Nspt_carga_product']\n",
        "    new_data[features_to_normalize] = scaler_X.transform(new_data[features_to_normalize])\n",
        "\n",
        "    # Previs√£o\n",
        "    pred_scaled = pipeline.predict(new_data[feature_names])\n",
        "    pred_real = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1))\n",
        "    print(f'\\nüìå Previs√£o da Carga: {pred_real.flatten()[0]:.2f} kN')\n",
        "    return pred_real.flatten()[0]\n",
        "\n",
        "# ----------------------------\n",
        "# Exemplo de uso do script\n",
        "# ----------------------------\n",
        "if __name__ == '__main__':\n",
        "    df = pd.read_csv('base_dataset3_carga.csv')\n",
        "    df_proc, scaler_X, scaler_y = preprocess_data(df)\n",
        "    model, features = train_model(df_proc)\n",
        "\n",
        "    novo_dado = pd.DataFrame({\n",
        "        'Deph(m)': [15],\n",
        "        'Nspt': [25],\n",
        "        'qc(Mpa)': [12.5],\n",
        "        'fs(Mpa)': [0.15]\n",
        "    })\n",
        "\n",
        "    predict_new_case(model, novo_dado, features, scaler_X, scaler_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IcF9kXBME3r7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}